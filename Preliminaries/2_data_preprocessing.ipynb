{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing\n",
    "\n",
    "To apply deep learning in the wild we must extract messy data stored in arbitrary formats, and preprocess it to suit our needs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating an artificial dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.makedirs(os.path.join('..', 'data'), exist_ok=True)\n",
    "data_file = os.path.join('..', 'data', 'house_tiny.csv')\n",
    "\n",
    "with open(data_file, 'w') as f:\n",
    "    f.write('''NumRooms,RoofType,Price\n",
    ",,127500\n",
    "2,,106000\n",
    "4,Slate,178100\n",
    ",,140000''')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **os.makedirs()**:is used to create a directory recursively. That means while making leaf directory if any intermediate-level directory is missing, os.makedirs() method will create them all\n",
    "\n",
    "    Parameters: \n",
    "\n",
    "1. path: A path-like object representing a file system path. A path-like object is either a string or bytes object representing a path.\n",
    "2. mode (optional) : A Integer value representing mode of the newly created directory..If this parameter is omitted then the default value Oo777 is used.\n",
    "3. exist_ok (optional) : A default value False is used for this parameter. If the target directory already exists an OSError is raised if its value is False otherwise not. For value True leaves directory unaltered. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the csv with pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   NumRooms RoofType   Price\n",
      "0       NaN      NaN  127500\n",
      "1       2.0      NaN  106000\n",
      "2       4.0    Slate  178100\n",
      "3       NaN      NaN  140000\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = pd.read_csv(data_file)\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- In supervised learning, separate the columns corresponding to input versus target values. We can select columns by name or via integer-location based indexig (iloc)\n",
    "- Nan values are missing values these values might be handled via imputation or deletion. \n",
    "    - imputation: replace missing values with estimates of their values.\n",
    "    - deletion: discards either those rows or those columns containing missing values\n",
    "- For categorical input fields we can treat NaN as a category."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0    127500\n",
       " 1    106000\n",
       " 2    178100\n",
       " 3    140000\n",
       " Name: Price, dtype: int64,\n",
       "    NumRooms RoofType\n",
       " 0       NaN      NaN\n",
       " 1       2.0      NaN\n",
       " 2       4.0    Slate\n",
       " 3       NaN      NaN)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs = data.iloc[:, 0:2]\n",
    "target = data.iloc[:,2]\n",
    "target, inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   NumRooms  RoofType_Slate  RoofType_nan\n",
      "0       NaN           False          True\n",
      "1       2.0           False          True\n",
      "2       4.0            True         False\n",
      "3       NaN           False          True\n"
     ]
    }
   ],
   "source": [
    "inputs = pd.get_dummies(inputs, dummy_na=True)\n",
    "print(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   NumRooms  RoofType_Slate  RoofType_nan\n",
      "0       3.0           False          True\n",
      "1       2.0           False          True\n",
      "2       4.0            True         False\n",
      "3       3.0           False          True\n"
     ]
    }
   ],
   "source": [
    "inputs = inputs.fillna(inputs.mean())\n",
    "print(inputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conversion to Tensor Format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[3., 0., 1.],\n",
       "         [2., 0., 1.],\n",
       "         [4., 1., 0.],\n",
       "         [3., 0., 1.]], dtype=torch.float64),\n",
       " tensor([127500., 106000., 178100., 140000.], dtype=torch.float64))"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "X = torch.tensor(inputs.to_numpy(dtype=float))\n",
    "y = torch.tensor(target.to_numpy(dtype=float))\n",
    "\n",
    "X,y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Discussion\n",
    "\n",
    "Data processing can get hairy. For example, rather than arriving in a single CSV file, our dataset might be spread across multiple files extracted from a relational database. For instance, in an e-commerce application, customer addresses might live in one table and purchase data in another. Moreover, practitioners face myriad data types beyond categorical and numeric, for example, text strings, images, audio data, and point clouds. Oftentimes, advanced tools and efficient algorithms are required in order to prevent data processing from becoming the biggest bottleneck in the machine learning pipeline. These problems will arise when we get to computer vision and natural language processing. Finally, we must pay attention to data quality. Real-world datasets are often plagued by outliers, faulty measurements from sensors, and recording errors, which must be addressed before feeding the data into any model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Excercises"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Excercise 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'uci_id': 1, 'name': 'Abalone', 'repository_url': 'https://archive.ics.uci.edu/dataset/1/abalone', 'data_url': 'https://archive.ics.uci.edu/static/public/1/data.csv', 'abstract': 'Predict the age of abalone from physical measurements', 'area': 'Biology', 'tasks': ['Classification', 'Regression'], 'characteristics': ['Tabular'], 'num_instances': 4177, 'num_features': 8, 'feature_types': ['Categorical', 'Integer', 'Real'], 'demographics': [], 'target_col': ['Rings'], 'index_col': None, 'has_missing_values': 'no', 'missing_values_symbol': None, 'year_of_dataset_creation': 1994, 'last_updated': 'Mon Aug 28 2023', 'dataset_doi': '10.24432/C55C7W', 'creators': ['Warwick Nash', 'Tracy Sellers', 'Simon Talbot', 'Andrew Cawthorn', 'Wes Ford'], 'intro_paper': None, 'additional_info': {'summary': 'Predicting the age of abalone from physical measurements.  The age of abalone is determined by cutting the shell through the cone, staining it, and counting the number of rings through a microscope -- a boring and time-consuming task.  Other measurements, which are easier to obtain, are used to predict the age.  Further information, such as weather patterns and location (hence food availability) may be required to solve the problem.\\r\\n\\r\\nFrom the original data examples with missing values were removed (the majority having the predicted value missing), and the ranges of the continuous values have been scaled for use with an ANN (by dividing by 200).', 'purpose': None, 'funded_by': None, 'instances_represent': None, 'recommended_data_splits': None, 'sensitive_data': None, 'preprocessing_description': None, 'variable_info': 'Given is the attribute name, attribute type, the measurement unit and a brief description.  The number of rings is the value to predict: either as a continuous value or as a classification problem.\\r\\n\\r\\nName / Data Type / Measurement Unit / Description\\r\\n-----------------------------\\r\\nSex / nominal / -- / M, F, and I (infant)\\r\\nLength / continuous / mm / Longest shell measurement\\r\\nDiameter\\t/ continuous / mm / perpendicular to length\\r\\nHeight / continuous / mm / with meat in shell\\r\\nWhole weight / continuous / grams / whole abalone\\r\\nShucked weight / continuous\\t / grams / weight of meat\\r\\nViscera weight / continuous / grams / gut weight (after bleeding)\\r\\nShell weight / continuous / grams / after being dried\\r\\nRings / integer / -- / +1.5 gives the age in years\\r\\n\\r\\nThe readme file contains attribute statistics.', 'citation': None}}\n",
      "             name     role         type demographic  \\\n",
      "0             Sex  Feature  Categorical        None   \n",
      "1          Length  Feature   Continuous        None   \n",
      "2        Diameter  Feature   Continuous        None   \n",
      "3          Height  Feature   Continuous        None   \n",
      "4    Whole_weight  Feature   Continuous        None   \n",
      "5  Shucked_weight  Feature   Continuous        None   \n",
      "6  Viscera_weight  Feature   Continuous        None   \n",
      "7    Shell_weight  Feature   Continuous        None   \n",
      "8           Rings   Target      Integer        None   \n",
      "\n",
      "                   description  units missing_values  \n",
      "0         M, F, and I (infant)   None             no  \n",
      "1    Longest shell measurement     mm             no  \n",
      "2      perpendicular to length     mm             no  \n",
      "3           with meat in shell     mm             no  \n",
      "4                whole abalone  grams             no  \n",
      "5               weight of meat  grams             no  \n",
      "6  gut weight (after bleeding)  grams             no  \n",
      "7            after being dried  grams             no  \n",
      "8  +1.5 gives the age in years   None             no  \n"
     ]
    }
   ],
   "source": [
    "#1\n",
    "from ucimlrepo import fetch_ucirepo \n",
    "  \n",
    "# fetch dataset \n",
    "abalone = fetch_ucirepo(id=1) \n",
    "  \n",
    "# data (as pandas dataframes) \n",
    "X = abalone.data.features \n",
    "y = abalone.data.targets \n",
    "  \n",
    "# metadata \n",
    "print(abalone.metadata) \n",
    "  \n",
    "# variable information \n",
    "print(abalone.variables) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(     Sex  Length  Diameter  Height  Whole_weight  Shucked_weight  \\\n",
       " 0      M   0.455     0.365   0.095        0.5140          0.2245   \n",
       " 1      M   0.350     0.265   0.090        0.2255          0.0995   \n",
       " 2      F   0.530     0.420   0.135        0.6770          0.2565   \n",
       " 3      M   0.440     0.365   0.125        0.5160          0.2155   \n",
       " 4      I   0.330     0.255   0.080        0.2050          0.0895   \n",
       " ...   ..     ...       ...     ...           ...             ...   \n",
       " 4172   F   0.565     0.450   0.165        0.8870          0.3700   \n",
       " 4173   M   0.590     0.440   0.135        0.9660          0.4390   \n",
       " 4174   M   0.600     0.475   0.205        1.1760          0.5255   \n",
       " 4175   F   0.625     0.485   0.150        1.0945          0.5310   \n",
       " 4176   M   0.710     0.555   0.195        1.9485          0.9455   \n",
       " \n",
       "       Viscera_weight  Shell_weight  \n",
       " 0             0.1010        0.1500  \n",
       " 1             0.0485        0.0700  \n",
       " 2             0.1415        0.2100  \n",
       " 3             0.1140        0.1550  \n",
       " 4             0.0395        0.0550  \n",
       " ...              ...           ...  \n",
       " 4172          0.2390        0.2490  \n",
       " 4173          0.2145        0.2605  \n",
       " 4174          0.2875        0.3080  \n",
       " 4175          0.2610        0.2960  \n",
       " 4176          0.3765        0.4950  \n",
       " \n",
       " [4177 rows x 8 columns],\n",
       "       Rings\n",
       " 0        15\n",
       " 1         7\n",
       " 2         9\n",
       " 3        10\n",
       " 4         7\n",
       " ...     ...\n",
       " 4172     11\n",
       " 4173     10\n",
       " 4174      9\n",
       " 4175     10\n",
       " 4176     12\n",
       " \n",
       " [4177 rows x 1 columns])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4177 entries, 0 to 4176\n",
      "Data columns (total 8 columns):\n",
      " #   Column          Non-Null Count  Dtype  \n",
      "---  ------          --------------  -----  \n",
      " 0   Sex             4177 non-null   object \n",
      " 1   Length          4177 non-null   float64\n",
      " 2   Diameter        4177 non-null   float64\n",
      " 3   Height          4177 non-null   float64\n",
      " 4   Whole_weight    4177 non-null   float64\n",
      " 5   Shucked_weight  4177 non-null   float64\n",
      " 6   Viscera_weight  4177 non-null   float64\n",
      " 7   Shell_weight    4177 non-null   float64\n",
      "dtypes: float64(7), object(1)\n",
      "memory usage: 261.2+ KB\n"
     ]
    }
   ],
   "source": [
    "X.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sex               0.0\n",
       "Length            0.0\n",
       "Diameter          0.0\n",
       "Height            0.0\n",
       "Whole_weight      0.0\n",
       "Shucked_weight    0.0\n",
       "Viscera_weight    0.0\n",
       "Shell_weight      0.0\n",
       "dtype: float64"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.isna().sum()/X.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Rings    0.0\n",
       "dtype: float64"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.isna().sum()/y.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- There are not missing values\n",
    "- There are only one categorial input the rest are numerical so 1/8 of the variables are categorical and 7/8 are numericals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.125, 0.875)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_categoricals = 0\n",
    "\n",
    "for column in X.columns:\n",
    "    if X[column].dtype == \"object\":\n",
    "        n_categoricals += 1\n",
    "\n",
    "ratio_categoricals = n_categoricals/len(list(X.columns))\n",
    "ratio_numericals = 1 - ratio_categoricals\n",
    "\n",
    "ratio_categoricals, ratio_numericals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Excercise 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Length</th>\n",
       "      <th>Diameter</th>\n",
       "      <th>Height</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.455</td>\n",
       "      <td>0.365</td>\n",
       "      <td>0.095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.350</td>\n",
       "      <td>0.265</td>\n",
       "      <td>0.090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.530</td>\n",
       "      <td>0.420</td>\n",
       "      <td>0.135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.440</td>\n",
       "      <td>0.365</td>\n",
       "      <td>0.125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.330</td>\n",
       "      <td>0.255</td>\n",
       "      <td>0.080</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Length  Diameter  Height\n",
       "0   0.455     0.365   0.095\n",
       "1   0.350     0.265   0.090\n",
       "2   0.530     0.420   0.135\n",
       "3   0.440     0.365   0.125\n",
       "4   0.330     0.255   0.080"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dimensions = X[[\"Length\",\"Diameter\",\"Height\"]]\n",
    "dimensions.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Whole_weight</th>\n",
       "      <th>Shucked_weight</th>\n",
       "      <th>Viscera_weight</th>\n",
       "      <th>Shell_weight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.5140</td>\n",
       "      <td>0.2245</td>\n",
       "      <td>0.1010</td>\n",
       "      <td>0.150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.2255</td>\n",
       "      <td>0.0995</td>\n",
       "      <td>0.0485</td>\n",
       "      <td>0.070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.6770</td>\n",
       "      <td>0.2565</td>\n",
       "      <td>0.1415</td>\n",
       "      <td>0.210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.5160</td>\n",
       "      <td>0.2155</td>\n",
       "      <td>0.1140</td>\n",
       "      <td>0.155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.0895</td>\n",
       "      <td>0.0395</td>\n",
       "      <td>0.055</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Whole_weight  Shucked_weight  Viscera_weight  Shell_weight\n",
       "0        0.5140          0.2245          0.1010         0.150\n",
       "1        0.2255          0.0995          0.0485         0.070\n",
       "2        0.6770          0.2565          0.1415         0.210\n",
       "3        0.5160          0.2155          0.1140         0.155\n",
       "4        0.2050          0.0895          0.0395         0.055"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights = X[[column for column in X.columns if column.endswith(\"weight\")]]\n",
    "weights.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    M\n",
       "1    M\n",
       "2    F\n",
       "3    M\n",
       "4    I\n",
       "Name: Sex, dtype: object"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sex = X[\"Sex\"]\n",
    "sex.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Excercise 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The dataset that i can load this way will depend of the amount of RAM that i have available\n",
    "- The limitations are the amount of RAM that depends on the size of the file, the amount of time to process the file that depends of the format\n",
    "- I am not sure about this question, I guess the difference will depend on the network connection to the server where probably the file format can have a major impact. Another big difference is going to be associated with the capacity of the laptop with respect to the capacity of the server. The server can probably handle much larger volumes of data than the laptop, but network limitations may slow down the workflow if data needs to be uploaded or downloaded."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**STRATEGIES**\n",
    "\n",
    "**Load Less Data**\n",
    "\n",
    "Supposed i want to load some columns of the Dataset but not all columns. We have 2 options:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>NumRooms</th>\n",
       "      <th>Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>127500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.0</td>\n",
       "      <td>106000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.0</td>\n",
       "      <td>178100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>140000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   NumRooms   Price\n",
       "0       NaN  127500\n",
       "1       2.0  106000\n",
       "2       4.0  178100\n",
       "3       NaN  140000"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Option 1: Load all and then filter what we need\n",
    "\n",
    "df = pd.read_csv(\"..\\data\\house_tiny.csv\")\n",
    "\n",
    "columns_target = [\"NumRooms\",\"Price\"]\n",
    "\n",
    "df[columns_target]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>NumRooms</th>\n",
       "      <th>Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>127500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.0</td>\n",
       "      <td>106000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.0</td>\n",
       "      <td>178100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>140000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   NumRooms   Price\n",
       "0       NaN  127500\n",
       "1       2.0  106000\n",
       "2       4.0  178100\n",
       "3       NaN  140000"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Option 2: Only load the columns we request\n",
    "\n",
    "df = pd.read_csv(\"..\\data\\house_tiny.csv\", usecols=columns_target)\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Use efficient datatypes**\n",
    "\n",
    "The default pandas data types are not the most memory efficient. This is especially true for text data columns with relatively few unique values (commonly referred to as “low-cardinality” data). By using more efficient data types, you can store larger datasets in memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index                128\n",
       "Sex               242266\n",
       "Length             33416\n",
       "Diameter           33416\n",
       "Height             33416\n",
       "Whole_weight       33416\n",
       "Shucked_weight     33416\n",
       "Viscera_weight     33416\n",
       "Shell_weight       33416\n",
       "dtype: int64"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.memory_usage(deep=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index               128\n",
       "Sex                4459\n",
       "Length            33416\n",
       "Diameter          33416\n",
       "Height            33416\n",
       "Whole_weight      33416\n",
       "Shucked_weight    33416\n",
       "Viscera_weight    33416\n",
       "Shell_weight      33416\n",
       "dtype: int64"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_2 = X.copy()\n",
    "\n",
    "X_2[\"Sex\"] = X_2[\"Sex\"].astype(\"category\")\n",
    "\n",
    "X_2.memory_usage(deep=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can go a bit further and downcast the numeric columns to their smallest types using pandas.to_numeric()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sex               category\n",
       "Length             float32\n",
       "Diameter           float32\n",
       "Height             float32\n",
       "Whole_weight       float32\n",
       "Shucked_weight     float32\n",
       "Viscera_weight     float32\n",
       "Shell_weight       float32\n",
       "dtype: object"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numerical_columns = X_2.iloc[:,1:].columns\n",
    "\n",
    "X_2[numerical_columns] = X_2[numerical_columns].apply(pd.to_numeric, downcast=\"float\")\n",
    "\n",
    "X_2.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index               128\n",
       "Sex                4459\n",
       "Length            16708\n",
       "Diameter          16708\n",
       "Height            16708\n",
       "Whole_weight      16708\n",
       "Shucked_weight    16708\n",
       "Viscera_weight    16708\n",
       "Shell_weight      16708\n",
       "dtype: int64"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_2.memory_usage(deep=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We’ve reduced the in-memory footprint of this dataset\n",
    "\n",
    "Source:\n",
    "- [Scaling to large datasets](https://pandas.pydata.org/docs/user_guide/scale.html)\n",
    "- [List of libraries implementing a DataFrame API](https://pandas.pydata.org/community/ecosystem.html) \n",
    "- [Enhancing performance](https://pandas.pydata.org/docs/user_guide/enhancingperf.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Excercise 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- If I have many categories, I would try to analyze how these categorical variables relate to each other and try to reduce variables that are high correlated, leaving only the most important of these correlated variables.\n",
    "- One way to work with high cardinality data is probably to try to process the data to group them in a more meaningful way or not consider this category at all."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Excercise 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [PIL](https://pillow.readthedocs.io/en/stable/handbook/tutorial.html)\n",
    "- [numpy.load](https://numpy.org/doc/stable/reference/generated/numpy.load.html)\n",
    "- [Dask](https://docs.dask.org/en/stable/)\n",
    "- [Ibis](https://ibis-project.org/tutorials/getting_started)\n",
    "- [Koalas](https://koalas.readthedocs.io/en/latest/)\n",
    "- [Modin](https://github.com/modin-project/modin)\n",
    "- [Odo](https://odo.pydata.org/en/latest/)\n",
    "- [Pandarell](https://github.com/nalepae/pandarallel)\n",
    "- [Ray](https://docs.ray.io/en/latest/data/api/doc/ray.data.from_pandas.html)\n",
    "- [Vaex](https://vaex.io/)\n",
    "- [Hail](https://hail.is/)\n",
    "- [NTV-pandas](https://github.com/loco-philippe/ntv-pandas)\n",
    "- [bcpandas](https://github.com/yehoshuadimarsky/bcpandas)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deep-learning-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
